import numpy as np
from scipy import stats
from urllib.request import urlopen
import urllib
import matplotlib.pyplot as plt # Visuals
import seaborn as sns 
import sklearn as skl
import pandas as pd
from pandas.plotting import scatter_matrix
from sklearn.grid_search import GridSearchCV
from sklearn import preprocessing
from sklearn.cross_validation import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier # Kth Nearest Neighbor
from sklearn.tree import DecisionTreeClassifier # Decision Trees
from sklearn.tree import export_graphviz # Extract Decision Tree visual
from sklearn.tree import tree 
from sklearn.ensemble import RandomForestClassifier # Random Forest
from sklearn import metrics
from sklearn.metrics import roc_curve # ROC Curves
from sklearn.metrics import auc # AUC 
from sklearn.model_selection import KFold, cross_val_score #cross validation 
from sklearn import cross_validation  #cross validation 
from urllib.request import urlopen # Get data from UCI Machine Learning Repository
import plotly.graph_objs as go
import plotly.plotly as py
import plotly.tools as pt

dataset = pd.read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])


'''1.Displaying sample data of 3-5 records'''
print(dataset.head)


'''starting of preprocessing process'''

'''2.Finding null values or missing data'''
print(dataset.isnull().sum())


'''3.Replacing null values(Filling)'''
dataset.replace('?',np.nan,inplace=True)
dataset=dataset.astype('float32')


values = dataset.values
dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])
dataset.to_csv('household_power_consumption.csv')

'''4.Visualizing the data'''

dataset.plot(kind='box',return_type='axes',color='green',sym='r*')

plt.show()

dataset.plot(kind='density');
plt.show();


'''7.Handling outliers using inter quartile range'''
Q1 = dataset.quantile(0.25)
Q3 = dataset.quantile(0.75)
IQR = Q3 - Q1
print(IQR)

'''8.Visulaizing the data'''
dataset.plot(kind='box',return_type='axes',color='green',sym='r*')
print(dataset.shape)


'''using z score'''
z = np.abs(stats.zscore(dataset))
dataset = dataset[(z < 3).all(axis=1)]
print(dataset.shape)
dataset = dataset[~((dataset < (Q1 - 1.5 * IQR)) |(dataset > (Q3 + 1.5 * IQR))).any(axis=1)]
print(dataset.shape)



'''10.normalization of data'''
def normalization_minmaxscaler(disease):
    dfnorm=disease.copy()
    for i in disease.columns:
        maxv=disease[i].max();
        minv=disease[i].min();
        dfnorm[i]=(disease[i]-minv)/(maxv-minv);
    return dfnorm
dfnorm=normalization_minmaxscaler(dataset);
dfnorm.plot(kind='box',return_type='axes',color='green',sym='r*')
plt.show()

'''11.Finding corelations'''
corr_mat=dataset.corr()
print(corr_mat)

'''



